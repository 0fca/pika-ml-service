﻿// This file was auto-generated by ML.NET Model Builder. 
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using Microsoft.ML.Data;
using Microsoft.ML.Trainers.LightGbm;
using Microsoft.ML.Trainers;
using Microsoft.ML;

namespace PikaMLModule
{
    public partial class WordSentimentModel
    {
        public static ITransformer RetrainPipeline(MLContext context, IDataView trainData)
        {
            var pipeline = BuildPipeline(context);
            var model = pipeline.Fit(trainData);

            return model;
        }

        /// <summary>
        /// build the pipeline that is used from model builder. Use this function to retrain model.
        /// </summary>
        /// <param name="mlContext"></param>
        /// <returns></returns>
        public static IEstimator<ITransformer> BuildPipeline(MLContext mlContext)
        {
            // Data process configuration with pipeline data transformations
            var pipeline = mlContext.Transforms.Text.FeaturizeText(@"example", @"example")      
                                    .Append(mlContext.Transforms.Concatenate(@"Features", @"example"))      
                                    .Append(mlContext.Transforms.Conversion.MapValueToKey(@"prediction_label", @"prediction_label"))      
                                    .Append(mlContext.MulticlassClassification.Trainers.LightGbm(new LightGbmMulticlassTrainer.Options(){NumberOfLeaves=4,MinimumExampleCountPerLeaf=32,NumberOfIterations=23,MaximumBinCountPerFeature=238,LearningRate=0.943127790244284F,LabelColumnName=@"prediction_label",FeatureColumnName=@"Features",Booster=new GradientBooster.Options(){SubsampleFraction=0.860402637447058F,FeatureFraction=0.740009348349834F,L1Regularization=9.07878317382097E-10F,L2Regularization=54.7726629778811F}}))      
                                    .Append(mlContext.Transforms.Conversion.MapKeyToValue(@"PredictedLabel", @"PredictedLabel"));

            return pipeline;
        }
    }
}
